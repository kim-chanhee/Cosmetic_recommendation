## 데이터 전처리

### 올리브영 웹사이트에서 수집된 스킨케어 제품(여드름 크림) 리뷰 데이터를 분석에 적합한 형태로 정제하고 토큰화하는 과정을 담고 있습니다. 원본 텍스트에 포함된 불필요한 요소들을 제거하고, 한국어 자연어 처리(NLP)를 위한 구조화된 데이터를 생성하는 것을 목표로 합니다.


💄 올리브영 리뷰 데이터 전처리 파이프라인
올리브영 리뷰 데이터 전처리 파이프라인 상세 분석
이 문서는 올리브영 리뷰 원본 데이터(여드름_크림_reviews_flat.csv)를 최종 분석용 데이터(Ntoken_review.csv)로 가공



---

### 1단계: 환경 설정 및 데이터 로딩
- 목표: 분석에 필요한 라이브러리를 불러오고, 여러 csv 파일에 분산된 원본 데이터를 하나의 데이터프레임으로 통합하여 분석 준비를 마칩니다.
- 처리 과정:
  1. pandas, numpy, konlpy, matplotlib, seaborn, wordcloud 등 데이터 처리, 자연어 처리, 시각화에 필요한 모든 라이브
  러리를 임포트합니다.
  2. 시각화 결과물에서 한글이 깨지지 않도록 matplotlib의 폰트 설정을 완료합니다.
  3. glob을 사용하여 지정된 폴더 내의 모든 .csv 파일을 찾아 리스트업하고, pd.concat 함수를 이용해 이들을 모두 합쳐 하나의 단일 DataFrame으로 생성합니다.
- 결과: 모든 리뷰 데이터가 통합된 df라는 이름의 DataFrame 객체가 생성됩니다.
  
---

### 2단계: 데이터 정제 (결측치 및 중복 제거)
- 목표: 데이터의 품질과 분석 결과의 신뢰도를 높이기 위해 불필요하거나 유효하지 않은 데이터를 제거합니다.
- 처리 과정:
  1. 결측치 제거: 분석의 핵심이 되는 review 컬럼을 기준으로, 내용이 비어있는 행(NaN)을 dropna() 함수를 통해 모두 제거합니다.
  2. 중복 제거: 완전히 동일한 내용의 리뷰가 중복으로 존재하는 경우, drop_duplicates() 함수를 사용하여 첫 번째 리뷰만 남기고 나머지는 모두 제거합니다.
- 결과: 결측치와 중복이 사라진, 순수하고 유효한 리뷰 데이터만 남게 됩니다.


[로드] 행:12347
[중복제거] 522건 제거 → 11795건 남음
[정제 완료] 최종 데이터 크기: (11795, 9)

<img width="334" height="345" alt="image" src="https://github.com/user-attachments/assets/4a5b91b3-f6c8-4e45-9f43-9581269cece7" />



---
  
### 3단계: 데이터 보강 (리뷰 텍스트에서 피부 타입 자동 추출)
- 목표: 사용자가 직접 입력하지 않아 비어있는('None') 'skin_type' 정보를 리뷰 본문 내용을 분석하여 자동으로 채워 넣어 데이터의 활용 가치를 높입니다.

- 처리 과정:
  1. 'skin_type' 컬럼이 'None'인 행들만 대상으로 작업을 수행합니다.
  2. 정규표현식을 사용해 'review' 컬럼 텍스트에서 '건성', '지성', '복합성', '민감성', '수부지' 등 피부 타입을 나타내는 키워드를 검색합니다.
  3. 키워드가 발견되면 해당 값을 비어있던 'skin_type' 컬럼에 채워 넣습니다. ('수부지'는 '지성'으로 통합 처리)
  4. 이 과정이 끝난 후, 보강된 피부 타입 데이터의 분포를 seaborn 막대그래프로 시각화하여 각 타입별 리뷰 수를 확인합니다.


- 데이터 변화:
  - Before (skin_type): None
  - After (skin_type): '지성' (리뷰 본문에 "저는 지성 피부인데..." 라는 내용이 있을 경우)

---

### 4단계: 텍스트 정규화
- 목표: 자연어 처리 분석의 효율을 높이기 위해, 모든 리뷰 텍스트를 일관된 형식으로 표준화합니다.

- 처리 과정:
  - re.sub 함수와 정규표현식을 활용하여 각 리뷰에서 한글, 영어, 숫자, 그리고 필수 구두점(.,?!)을 제외한 모든 특수문자, 이모티콘, 공백 등을 제거합니다.

- 데이터 변화:
  - Before (review): b5제품을 만난 이뢰로 계속 재구매중입니다.👍 흡수가 빠르고...
  - After (review): b5제품을 만난 이뢰로 계속 재구매중입니다. 흡수가 빠르고...

---

### 5단계: 자연어 처리 (형태소 분석 및 키워드 추출)
- 목표: 정규화된 텍스트를 의미 단위(형태소)로 분해하고, 그중 분석에 핵심적인 품사(명사, 동사, 형용사)만을 추출하여 키워드셋을 구축합니다.

- 처리 과정:
1. 형태소 분석: Konlpy의 Komoran 형태소 분석기를 사용하여 각 리뷰 문장을 형태소 단위로 나누고, 각 형태소에 품사 정보를 태깅합니다. (tokens_pos 컬럼 생성)
2. 핵심 품사 추출: 태깅된 결과에서 명사(NNG, NNP), 동사(VV), **형용사(VA)**에 해당하는 형태소만 선별합니다. 동사는 원형인 '-다'를 붙여 일반화합니다. (keywords 컬럼 생성)
3. 불용어 제거: '제품', '사용', '너무'와 같이 빈번하게 등장하지만 분석에 큰 의미가 없는 단어들을 사용자 정의 사전을 기반으로 제거하여 최종 키워드 리스트를 완성합니다. (Ntoken_review 컬럼 생성)

- 데이터 변화:
  - tokens_pos 결과: [('제품', 'NNG'), ('흡수', 'NNG'), ('빠르', 'VA')]
  - Ntoken_review 최종 결과: ['흡수', '빠르다']


<img width="1990" height="989" alt="image" src="https://github.com/user-attachments/assets/02a65c48-5b36-4b21-9ac4-054897872bed" />


---

### 6단계: 최종 결과 저장 및 시각화
- 목표: 모든 처리 과정을 거친 최종 데이터를 .csv 파일로 저장하고, 추출된 핵심 키워드의 빈도를 한눈에 파악할 수 있도록 워드클라우드로 시각화합니다.

- 처리 과정:
1. 분석에 필요한 최종 컬럼들(review, Ntoken_review 등)을 선택하여 Ntoken_review.csv 파일로 저장합니다.
2. Ntoken_review 컬럼에 있는 모든 키워드를 하나의 리스트로 통합합니다.
3. WordCloud 라이브러리를 사용하여 키워드의 등장 빈도에 따라 크기가 다른 단어들로 구성된 이미지를 생성합니다.

- 결과물:
  1. Ntoken_review.csv 파일: 모든 전처리가 완료된, 구조화된 최종 데이터셋.
  2. 워드클라우드 이미지: 리뷰 전반에서 가장 중요하게 언급되는 키워드들을 시각적으로 표현한 자료

📈 결과 예시 (워드클라우드)
<img width="1182" height="631" alt="image" src="https://github.com/user-attachments/assets/372c6520-1fcb-4ac6-afa8-195fd9fe5268" />
