{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "# import numpy as np\n",
    "# # CSV íŒŒì¼ ë¶ˆëŸ¬ì˜¤ê¸°\n",
    "# senti_df = pd.read_csv(\"/Users/Shared/ìµœì¢…ì„ _êµìˆ˜ë‹˜/Face_skin_disease/ê°ì„±ë¶„ì„/ê°ì„±ì‚¬ì „/senti_labeled_df.csv\")\n",
    "# ntoken_df = pd.read_csv(\"/Users/Shared/ìµœì¢…ì„ _êµìˆ˜ë‹˜/Face_skin_disease/ë°ì´í„° ì „ì²˜ë¦¬/í”¼ë¶€ ì§ˆí™˜ í™”ì¥í’ˆ ë°ì´í„°/ì—¬ë“œë¦„_ìŠ¤í‚¨ì¼€ì–´/í¬ë¦¼/Ntoken_review.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # senti_labeled_df.csv ì˜ pred ì—´ë§Œ ì¶”ì¶œ\n",
    "# pred_col = senti_df[[\"pred\"]]\n",
    "\n",
    "# # ë‘ ë°ì´í„°í”„ë ˆì„ í•©ì¹˜ê¸° (ì¸ë±ìŠ¤ ê¸°ì¤€)\n",
    "# merged_df = pd.concat([ntoken_df, pred_col], axis=1)\n",
    "\n",
    "# # ê²°ê³¼ ì €ì¥\n",
    "# merged_df.to_csv(\"merged_output.csv\", index=False)\n",
    "\n",
    "# print(\"ë³‘í•© ì™„ë£Œ! merged_output.csv ìƒì„±ë¨.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… ëª¨ë“  ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„í¬íŠ¸ ì™„ë£Œ.\n"
     ]
    }
   ],
   "source": [
    "## ===================================================================\n",
    "## 1. ê¸°ë³¸ ì„¤ì • ë° ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„í¬íŠ¸\n",
    "## ===================================================================\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from ast import literal_eval\n",
    "import torch\n",
    "from typing import Optional, List, Dict\n",
    "\n",
    "# ì¶”ì²œ ëª¨ë¸ìš©\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "# ê°ì„± ë¶„ì„ ëª¨ë¸ìš©\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, LSTM, Dense, Dropout, GlobalAveragePooling1D\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "\n",
    "# Surprise (í˜‘ì—… í•„í„°ë§ìš©)\n",
    "try:\n",
    "    from surprise import Dataset, Reader, SVD\n",
    "    HAS_SURPRISE = True\n",
    "except ImportError:\n",
    "    HAS_SURPRISE = False\n",
    "    print(\"âš ï¸ Surpriseê°€ ì„¤ì¹˜ë˜ì§€ ì•Šì•„ í˜‘ì—… í•„í„°ë§(SVD)ì„ ê±´ë„ˆëœë‹ˆë‹¤. í•„ìš”ì‹œ %pip install scikit-surprise ì‹¤í–‰í•˜ì„¸ìš”.\")\n",
    "\n",
    "print(\"âœ… ëª¨ë“  ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„í¬íŠ¸ ì™„ë£Œ.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… ë°ì´í„° ì¤€ë¹„ ì™„ë£Œ (ì´ 11795ê°œ ë¦¬ë·°, 20ê°œ ì œí’ˆ)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>item_id</th>\n",
       "      <th>user_id</th>\n",
       "      <th>skin_type</th>\n",
       "      <th>skin_tone</th>\n",
       "      <th>skin_concerns</th>\n",
       "      <th>review</th>\n",
       "      <th>date</th>\n",
       "      <th>rating</th>\n",
       "      <th>gender</th>\n",
       "      <th>tokens</th>\n",
       "      <th>Ntoken_review</th>\n",
       "      <th>pred</th>\n",
       "      <th>text</th>\n",
       "      <th>rating_aug</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ë¼ë¡œìŠˆí¬ì œ ì‹œì¹´í”Œë¼ìŠ¤íŠ¸ ë©€í‹° ë¦¬í˜ì–´ í¬ë¦¼ 100ml (+15ml+ì‹œì¹´ë°¤3ml+ì‹œì¹´ì„ ...</td>\n",
       "      <td>vwaaang</td>\n",
       "      <td>ê±´ì„±</td>\n",
       "      <td>ì¿¨í†¤</td>\n",
       "      <td>ê°ì§ˆ / ëª¨ê³µ</td>\n",
       "      <td>ì œí’ˆì„ ë§Œë‚œ ì´ë¢°ë¡œ ê³„ì† ì¬êµ¬ë§¤ì¤‘ì…ë‹ˆë‹¤ í¡ìˆ˜ê°€ ë¹ ë¥´ê³  ì–¼êµ´ì— ìê³  ì¼ì–´ë‚˜ë©´ ì–¼êµ´ì— ...</td>\n",
       "      <td>2025.09.17</td>\n",
       "      <td>5.0</td>\n",
       "      <td>ì—¬ì„±</td>\n",
       "      <td>[('ì œí’ˆ', 'NNG'), ('ì„', 'JKO'), ('ë§Œë‚˜', 'VV'), ('...</td>\n",
       "      <td>['ì œí’ˆ', 'êµ¬ë§¤', 'í¡ìˆ˜', 'ì–¼êµ´', 'ì–¼êµ´', 'ìœ ë¶„ê¸°', 'ì—¬ë“œë¦„', '...</td>\n",
       "      <td>0</td>\n",
       "      <td>ì œí’ˆì„ ë§Œë‚œ ì´ë¢°ë¡œ ê³„ì† ì¬êµ¬ë§¤ì¤‘ì…ë‹ˆë‹¤ í¡ìˆ˜ê°€ ë¹ ë¥´ê³  ì–¼êµ´ì— ìê³  ì¼ì–´ë‚˜ë©´ ì–¼êµ´ì— ...</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ë¼ë¡œìŠˆí¬ì œ ì‹œì¹´í”Œë¼ìŠ¤íŠ¸ ë©€í‹° ë¦¬í˜ì–´ í¬ë¦¼ 100ml (+15ml+ì‹œì¹´ë°¤3ml+ì‹œì¹´ì„ ...</td>\n",
       "      <td>ë‚˜ì´ê±°ê°€ì‚¬ë¡œì¨ë„ë¼</td>\n",
       "      <td>ê±´ì„±</td>\n",
       "      <td>ì›œí†¤</td>\n",
       "      <td>ë¯¼ê°ì„± / íŠ¸ëŸ¬ë¸”</td>\n",
       "      <td>ì•„ë§ˆë„ ìˆ˜ë¶€ì§€ì¸ í”¼ë¶€ì¸ë° ì´ê±° ë°”ë¥´ê³  í”¼ë¶€ ë‹¤ ë’¤ì§‘ì–´ì ¸ì„œ í•œë²ˆ ì“°ê³  ë°”ë¡œ ë‹¤ë¥¸ ì˜ë§...</td>\n",
       "      <td>2025.09.07</td>\n",
       "      <td>1.0</td>\n",
       "      <td>ì—¬ì„±</td>\n",
       "      <td>[('ì•„ë§ˆë„', 'MAG'), ('ìˆ˜ë¶€ì§€', 'NNG'), ('ì´', 'VCP'),...</td>\n",
       "      <td>['ìˆ˜ë¶€ì§€', 'í”¼ë¶€', 'í”¼ë¶€', 'ì‚¬ëŒ']</td>\n",
       "      <td>0</td>\n",
       "      <td>ì•„ë§ˆë„ ìˆ˜ë¶€ì§€ì¸ í”¼ë¶€ì¸ë° ì´ê±° ë°”ë¥´ê³  í”¼ë¶€ ë‹¤ ë’¤ì§‘ì–´ì ¸ì„œ í•œë²ˆ ì“°ê³  ë°”ë¡œ ë‹¤ë¥¸ ì˜ë§...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ë¼ë¡œìŠˆí¬ì œ ì‹œì¹´í”Œë¼ìŠ¤íŠ¸ ë©€í‹° ë¦¬í˜ì–´ í¬ë¦¼ 100ml (+15ml+ì‹œì¹´ë°¤3ml+ì‹œì¹´ì„ ...</td>\n",
       "      <td>ì°ì§€ë§ë¼ì˜¹</td>\n",
       "      <td>ë³µí•©ì„±</td>\n",
       "      <td>ê²¨ìš¸ì¿¨í†¤</td>\n",
       "      <td>ê°ì§ˆ / ëª¨ê³µ</td>\n",
       "      <td>ì™€ ì •ë§ ìˆœí•˜ë„¤ìš” ê°€ê²©ì´ ì„ì„œ ì‚´ê¹Œë§ê¹Œí•˜ë‹¤ê°€ ê²°êµ­ ìƒ€ëŠ”ë° í›„íšŒ  ë„ ì—†ì–´ìš” ì €ëŠ”  ...</td>\n",
       "      <td>2025.09.25</td>\n",
       "      <td>5.0</td>\n",
       "      <td>ì—¬ì„±</td>\n",
       "      <td>[('ì˜¤', 'VV'), ('ì•„', 'EC'), ('ì •ë§', 'MAG'), ('ìˆœí•˜...</td>\n",
       "      <td>['ê°€ê²©', 'í›„íšŒ']</td>\n",
       "      <td>0</td>\n",
       "      <td>ì™€ ì •ë§ ìˆœí•˜ë„¤ìš” ê°€ê²©ì´ ì„ì„œ ì‚´ê¹Œë§ê¹Œí•˜ë‹¤ê°€ ê²°êµ­ ìƒ€ëŠ”ë° í›„íšŒ  ë„ ì—†ì–´ìš” ì €ëŠ”  ...</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ë¼ë¡œìŠˆí¬ì œ ì‹œì¹´í”Œë¼ìŠ¤íŠ¸ ë©€í‹° ë¦¬í˜ì–´ í¬ë¦¼ 100ml (+15ml+ì‹œì¹´ë°¤3ml+ì‹œì¹´ì„ ...</td>\n",
       "      <td>ê¿€í”¼ë¶€ì´‰ì´‰</td>\n",
       "      <td>ë³µí•©ì„±</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ì¬ì¬ì¬êµ¬ë§¤ í”¼ë¶€ì¥ë²½ íŠ¼íŠ¼í•´ì§‘ë‹ˆë‹¤  íŠ¸ëŸ¬ë¸” ê´€ë ¨ ì„¸ëŸ¼ì— ì´ê±° ë“œìŒë¿ ì•„ë‚Œì—†ì´ ë°”ë¦…ë‹ˆë‹¤...</td>\n",
       "      <td>2025.09.26</td>\n",
       "      <td>5.0</td>\n",
       "      <td>ì—¬ì„±</td>\n",
       "      <td>[('ì¬', 'XPN'), ('ì¬', 'XPN'), ('ì¬', 'XPN'), ('êµ¬...</td>\n",
       "      <td>['êµ¬ë§¤', 'í”¼ë¶€ì¥ë²½', 'íŠ¸ëŸ¬ë¸”', 'ê´€ë ¨', 'íŠ¸ëŸ¬ë¸”', 'ì™„í™”', 'ì¥ë²½',...</td>\n",
       "      <td>0</td>\n",
       "      <td>ì¬ì¬ì¬êµ¬ë§¤ í”¼ë¶€ì¥ë²½ íŠ¼íŠ¼í•´ì§‘ë‹ˆë‹¤  íŠ¸ëŸ¬ë¸” ê´€ë ¨ ì„¸ëŸ¼ì— ì´ê±° ë“œìŒë¿ ì•„ë‚Œì—†ì´ ë°”ë¦…ë‹ˆë‹¤...</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ë¼ë¡œìŠˆí¬ì œ ì‹œì¹´í”Œë¼ìŠ¤íŠ¸ ë©€í‹° ë¦¬í˜ì–´ í¬ë¦¼ 100ml (+15ml+ì‹œì¹´ë°¤3ml+ì‹œì¹´ì„ ...</td>\n",
       "      <td>ì•…ì•…ì•…ì•…ì§€ì„±</td>\n",
       "      <td>ì§€ì„±</td>\n",
       "      <td>ë´„ì›œí†¤</td>\n",
       "      <td>ê°ì§ˆ / ë‹¤í¬ì„œí´</td>\n",
       "      <td>ê·¹ì§€ì„±ì— ì‹¬ê°í•œ ì—¬ë“œë¦„ í”¼ë¶€ë¼ ì‹œì–´ë²„í„°ê°™ì€ ì—¬ë“œë¦„ ìœ ë°œí•˜ëŠ” ì„±ë¶„ì´ë‚˜ ëª¨ê³µë§‰ëŠ” ì„±ë¶„ ...</td>\n",
       "      <td>2025.10.01</td>\n",
       "      <td>3.0</td>\n",
       "      <td>ì—¬ì„±</td>\n",
       "      <td>[('ê·¹', 'NNG'), ('ì§€ì„±', 'NNG'), ('ì—', 'JKB'), ('...</td>\n",
       "      <td>['ì§€ì„±', 'ì—¬ë“œë¦„', 'í”¼ë¶€', 'ì‹œì–´ë²„í„°', 'ì—¬ë“œë¦„', 'ìœ ë°œ', 'ì„±ë¶„',...</td>\n",
       "      <td>0</td>\n",
       "      <td>ê·¹ì§€ì„±ì— ì‹¬ê°í•œ ì—¬ë“œë¦„ í”¼ë¶€ë¼ ì‹œì–´ë²„í„°ê°™ì€ ì—¬ë“œë¦„ ìœ ë°œí•˜ëŠ” ì„±ë¶„ì´ë‚˜ ëª¨ê³µë§‰ëŠ” ì„±ë¶„ ...</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             item_id    user_id skin_type  \\\n",
       "0  ë¼ë¡œìŠˆí¬ì œ ì‹œì¹´í”Œë¼ìŠ¤íŠ¸ ë©€í‹° ë¦¬í˜ì–´ í¬ë¦¼ 100ml (+15ml+ì‹œì¹´ë°¤3ml+ì‹œì¹´ì„ ...    vwaaang        ê±´ì„±   \n",
       "1  ë¼ë¡œìŠˆí¬ì œ ì‹œì¹´í”Œë¼ìŠ¤íŠ¸ ë©€í‹° ë¦¬í˜ì–´ í¬ë¦¼ 100ml (+15ml+ì‹œì¹´ë°¤3ml+ì‹œì¹´ì„ ...  ë‚˜ì´ê±°ê°€ì‚¬ë¡œì¨ë„ë¼        ê±´ì„±   \n",
       "2  ë¼ë¡œìŠˆí¬ì œ ì‹œì¹´í”Œë¼ìŠ¤íŠ¸ ë©€í‹° ë¦¬í˜ì–´ í¬ë¦¼ 100ml (+15ml+ì‹œì¹´ë°¤3ml+ì‹œì¹´ì„ ...      ì°ì§€ë§ë¼ì˜¹       ë³µí•©ì„±   \n",
       "3  ë¼ë¡œìŠˆí¬ì œ ì‹œì¹´í”Œë¼ìŠ¤íŠ¸ ë©€í‹° ë¦¬í˜ì–´ í¬ë¦¼ 100ml (+15ml+ì‹œì¹´ë°¤3ml+ì‹œì¹´ì„ ...      ê¿€í”¼ë¶€ì´‰ì´‰       ë³µí•©ì„±   \n",
       "4  ë¼ë¡œìŠˆí¬ì œ ì‹œì¹´í”Œë¼ìŠ¤íŠ¸ ë©€í‹° ë¦¬í˜ì–´ í¬ë¦¼ 100ml (+15ml+ì‹œì¹´ë°¤3ml+ì‹œì¹´ì„ ...     ì•…ì•…ì•…ì•…ì§€ì„±        ì§€ì„±   \n",
       "\n",
       "  skin_tone skin_concerns                                             review  \\\n",
       "0        ì¿¨í†¤       ê°ì§ˆ / ëª¨ê³µ  ì œí’ˆì„ ë§Œë‚œ ì´ë¢°ë¡œ ê³„ì† ì¬êµ¬ë§¤ì¤‘ì…ë‹ˆë‹¤ í¡ìˆ˜ê°€ ë¹ ë¥´ê³  ì–¼êµ´ì— ìê³  ì¼ì–´ë‚˜ë©´ ì–¼êµ´ì— ...   \n",
       "1        ì›œí†¤     ë¯¼ê°ì„± / íŠ¸ëŸ¬ë¸”  ì•„ë§ˆë„ ìˆ˜ë¶€ì§€ì¸ í”¼ë¶€ì¸ë° ì´ê±° ë°”ë¥´ê³  í”¼ë¶€ ë‹¤ ë’¤ì§‘ì–´ì ¸ì„œ í•œë²ˆ ì“°ê³  ë°”ë¡œ ë‹¤ë¥¸ ì˜ë§...   \n",
       "2      ê²¨ìš¸ì¿¨í†¤       ê°ì§ˆ / ëª¨ê³µ  ì™€ ì •ë§ ìˆœí•˜ë„¤ìš” ê°€ê²©ì´ ì„ì„œ ì‚´ê¹Œë§ê¹Œí•˜ë‹¤ê°€ ê²°êµ­ ìƒ€ëŠ”ë° í›„íšŒ  ë„ ì—†ì–´ìš” ì €ëŠ”  ...   \n",
       "3       NaN           NaN  ì¬ì¬ì¬êµ¬ë§¤ í”¼ë¶€ì¥ë²½ íŠ¼íŠ¼í•´ì§‘ë‹ˆë‹¤  íŠ¸ëŸ¬ë¸” ê´€ë ¨ ì„¸ëŸ¼ì— ì´ê±° ë“œìŒë¿ ì•„ë‚Œì—†ì´ ë°”ë¦…ë‹ˆë‹¤...   \n",
       "4       ë´„ì›œí†¤     ê°ì§ˆ / ë‹¤í¬ì„œí´  ê·¹ì§€ì„±ì— ì‹¬ê°í•œ ì—¬ë“œë¦„ í”¼ë¶€ë¼ ì‹œì–´ë²„í„°ê°™ì€ ì—¬ë“œë¦„ ìœ ë°œí•˜ëŠ” ì„±ë¶„ì´ë‚˜ ëª¨ê³µë§‰ëŠ” ì„±ë¶„ ...   \n",
       "\n",
       "         date  rating gender  \\\n",
       "0  2025.09.17     5.0     ì—¬ì„±   \n",
       "1  2025.09.07     1.0     ì—¬ì„±   \n",
       "2  2025.09.25     5.0     ì—¬ì„±   \n",
       "3  2025.09.26     5.0     ì—¬ì„±   \n",
       "4  2025.10.01     3.0     ì—¬ì„±   \n",
       "\n",
       "                                              tokens  \\\n",
       "0  [('ì œí’ˆ', 'NNG'), ('ì„', 'JKO'), ('ë§Œë‚˜', 'VV'), ('...   \n",
       "1  [('ì•„ë§ˆë„', 'MAG'), ('ìˆ˜ë¶€ì§€', 'NNG'), ('ì´', 'VCP'),...   \n",
       "2  [('ì˜¤', 'VV'), ('ì•„', 'EC'), ('ì •ë§', 'MAG'), ('ìˆœí•˜...   \n",
       "3  [('ì¬', 'XPN'), ('ì¬', 'XPN'), ('ì¬', 'XPN'), ('êµ¬...   \n",
       "4  [('ê·¹', 'NNG'), ('ì§€ì„±', 'NNG'), ('ì—', 'JKB'), ('...   \n",
       "\n",
       "                                       Ntoken_review  pred  \\\n",
       "0  ['ì œí’ˆ', 'êµ¬ë§¤', 'í¡ìˆ˜', 'ì–¼êµ´', 'ì–¼êµ´', 'ìœ ë¶„ê¸°', 'ì—¬ë“œë¦„', '...     0   \n",
       "1                          ['ìˆ˜ë¶€ì§€', 'í”¼ë¶€', 'í”¼ë¶€', 'ì‚¬ëŒ']     0   \n",
       "2                                       ['ê°€ê²©', 'í›„íšŒ']     0   \n",
       "3  ['êµ¬ë§¤', 'í”¼ë¶€ì¥ë²½', 'íŠ¸ëŸ¬ë¸”', 'ê´€ë ¨', 'íŠ¸ëŸ¬ë¸”', 'ì™„í™”', 'ì¥ë²½',...     0   \n",
       "4  ['ì§€ì„±', 'ì—¬ë“œë¦„', 'í”¼ë¶€', 'ì‹œì–´ë²„í„°', 'ì—¬ë“œë¦„', 'ìœ ë°œ', 'ì„±ë¶„',...     0   \n",
       "\n",
       "                                                text  rating_aug  \n",
       "0  ì œí’ˆì„ ë§Œë‚œ ì´ë¢°ë¡œ ê³„ì† ì¬êµ¬ë§¤ì¤‘ì…ë‹ˆë‹¤ í¡ìˆ˜ê°€ ë¹ ë¥´ê³  ì–¼êµ´ì— ìê³  ì¼ì–´ë‚˜ë©´ ì–¼êµ´ì— ...         5.0  \n",
       "1  ì•„ë§ˆë„ ìˆ˜ë¶€ì§€ì¸ í”¼ë¶€ì¸ë° ì´ê±° ë°”ë¥´ê³  í”¼ë¶€ ë‹¤ ë’¤ì§‘ì–´ì ¸ì„œ í•œë²ˆ ì“°ê³  ë°”ë¡œ ë‹¤ë¥¸ ì˜ë§...         1.0  \n",
       "2  ì™€ ì •ë§ ìˆœí•˜ë„¤ìš” ê°€ê²©ì´ ì„ì„œ ì‚´ê¹Œë§ê¹Œí•˜ë‹¤ê°€ ê²°êµ­ ìƒ€ëŠ”ë° í›„íšŒ  ë„ ì—†ì–´ìš” ì €ëŠ”  ...         5.0  \n",
       "3  ì¬ì¬ì¬êµ¬ë§¤ í”¼ë¶€ì¥ë²½ íŠ¼íŠ¼í•´ì§‘ë‹ˆë‹¤  íŠ¸ëŸ¬ë¸” ê´€ë ¨ ì„¸ëŸ¼ì— ì´ê±° ë“œìŒë¿ ì•„ë‚Œì—†ì´ ë°”ë¦…ë‹ˆë‹¤...         5.0  \n",
       "4  ê·¹ì§€ì„±ì— ì‹¬ê°í•œ ì—¬ë“œë¦„ í”¼ë¶€ë¼ ì‹œì–´ë²„í„°ê°™ì€ ì—¬ë“œë¦„ ìœ ë°œí•˜ëŠ” ì„±ë¶„ì´ë‚˜ ëª¨ê³µë§‰ëŠ” ì„±ë¶„ ...         3.0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# ===================================================================\n",
    "# 2. ë°ì´í„° ì¤€ë¹„ ë° íŠ¹ì„± ìƒì„±\n",
    "# ===================================================================\n",
    "file_path = \"merged_output.csv\"\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# ì‚¬ìš©ì í™•ì¸ ì»¬ëŸ¼: product_name, customer_name, skin_type, skin_tone, \n",
    "#                  skin_concern_1, skin_concern_2, review, review_date(date), rating, pred\n",
    "# gender, tokens, Ntoken_review ë“±ë„ í¬í•¨ í™•ì¸\n",
    "\n",
    "df.rename(columns={\n",
    "    'customer_name': 'user_id',\n",
    "    'product_name': 'item_id'\n",
    "}, inplace=True)\n",
    "\n",
    "# 'tokens' ì»¬ëŸ¼ì˜ ë¦¬ìŠ¤íŠ¸ë¥¼ ê³µë°±ìœ¼ë¡œ ì—°ê²°í•˜ëŠ” í•¨ìˆ˜\n",
    "def join_tokens(x):\n",
    "    try:\n",
    "        x_list = literal_eval(x) if isinstance(x, str) else x\n",
    "        if isinstance(x_list, list):\n",
    "            return \" \".join(map(str, x_list))\n",
    "    except (ValueError, SyntaxError):\n",
    "        pass\n",
    "    return str(x) if pd.notna(x) else \"\"\n",
    "\n",
    "# ì½˜í…ì¸  ê¸°ë°˜ ì¶”ì²œì„ ìœ„í•œ í…ìŠ¤íŠ¸ í†µí•©\n",
    "df[\"text\"] = df[\"review\"].fillna(\"\") + \" \" + (df[\"Ntoken_review\"].apply(join_tokens) if \"Ntoken_review\" in df.columns else \"\")\n",
    "\n",
    "# í˜‘ì—… í•„í„°ë§ì„ ìœ„í•œ í‰ì  ë³´ì •\n",
    "df[\"rating_aug\"] = (df[\"rating\"].astype(float) + 0.5 * df.get(\"pred\", 0)).clip(0.5, 5.0)\n",
    "\n",
    "# ì•„ì´í…œë³„ ì •ë³´ ì§‘ê³„ ë° ì¸ë±ìŠ¤ ìƒì„±\n",
    "item_text_df = df.groupby(\"item_id\")[\"text\"].apply(lambda s: \" \".join(map(str, s))).reset_index()\n",
    "item_to_idx = {item_id: i for i, item_id in enumerate(item_text_df[\"item_id\"])}\n",
    "idx_to_item = {i: item_id for item_id, i in item_to_idx.items()}\n",
    "\n",
    "print(f\"âœ… ë°ì´í„° ì¤€ë¹„ ì™„ë£Œ (ì´ {len(df)}ê°œ ë¦¬ë·°, {len(item_text_df)}ê°œ ì œí’ˆ)\")\n",
    "display(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KoBERT ëª¨ë¸ì„ 'mps'ì—ì„œ ì‹¤í–‰í•©ë‹ˆë‹¤.\n",
      "âœ… KoBERT ë²¡í„° ìƒì„± ë° ì½˜í…ì¸  ê¸°ë°˜ ì¶”ì²œ í•¨ìˆ˜ ì •ì˜ ì™„ë£Œ\n"
     ]
    }
   ],
   "source": [
    "# ===================================================================\n",
    "# 3. ì½˜í…ì¸  ê¸°ë°˜ ì¶”ì²œ (KoBERT)\n",
    "# ===================================================================\n",
    "MODEL_NAME = \"monologg/kobert\"\n",
    "DEVICE = torch.device(\"mps\" if torch.backends.mps.is_available() else (\"cuda\" if torch.cuda.is_available() else \"cpu\"))\n",
    "print(f\"KoBERT ëª¨ë¸ì„ '{DEVICE}'ì—ì„œ ì‹¤í–‰í•©ë‹ˆë‹¤.\")\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
    "bert_model = AutoModel.from_pretrained(MODEL_NAME).to(DEVICE).eval()\n",
    "\n",
    "@torch.no_grad()\n",
    "def encode_texts(texts: list, batch_size: int = 16) -> np.ndarray:\n",
    "    output_vectors = []\n",
    "    for i in range(0, len(texts), batch_size):\n",
    "        batch_texts = texts[i:i + batch_size]\n",
    "        encodings = tokenizer(batch_texts, padding=True, truncation=True, max_length=128, return_tensors=\"pt\").to(DEVICE)\n",
    "        mean_pooled_emb = bert_model(**encodings).last_hidden_state.mean(dim=1)\n",
    "        output_vectors.append(torch.nn.functional.normalize(mean_pooled_emb, p=2, dim=1).cpu())\n",
    "    return torch.vstack(output_vectors).numpy()\n",
    "\n",
    "X_item_txt = encode_texts(item_text_df[\"text\"].tolist())\n",
    "\n",
    "def get_user_text_profile(df: pd.DataFrame, user_id: str) -> Optional[np.ndarray]:\n",
    "    liked_reviews = df[(df.user_id == user_id) & (df.rating >= 4.0)]\n",
    "    item_indices = [item_to_idx[i] for i in liked_reviews.item_id if i in item_to_idx]\n",
    "    if not item_indices: return None\n",
    "    weights = liked_reviews.loc[liked_reviews.item_id.isin(item_to_idx), \"rating\"].values\n",
    "    weights = (weights / (weights.sum() + 1e-8))[:, None]\n",
    "    profile_vector = (X_item_txt[item_indices] * weights).sum(0, keepdims=True)\n",
    "    return profile_vector / (np.linalg.norm(profile_vector, axis=1, keepdims=True) + 1e-9)\n",
    "\n",
    "def recommend_content_based(df: pd.DataFrame, user_id: str, k: int = 1000) -> Dict[str, float]:\n",
    "    user_profile = get_user_text_profile(df, user_id)\n",
    "    if user_profile is None: return {}\n",
    "    similarities = cosine_similarity(user_profile, X_item_txt).ravel()\n",
    "    return {idx_to_item[i]: float(similarities[i]) for i in np.argsort(similarities)[::-1][:k]}\n",
    "\n",
    "print(f\"âœ… KoBERT ë²¡í„° ìƒì„± ë° ì½˜í…ì¸  ê¸°ë°˜ ì¶”ì²œ í•¨ìˆ˜ ì •ì˜ ì™„ë£Œ\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… SVD ëª¨ë¸ í•™ìŠµ ì™„ë£Œ.\n",
      "âœ… í˜‘ì—… í•„í„°ë§ ì¶”ì²œ í•¨ìˆ˜ ì •ì˜ ì™„ë£Œ.\n"
     ]
    }
   ],
   "source": [
    "# ===================================================================\n",
    "# 4. í˜‘ì—… í•„í„°ë§ ì¶”ì²œ (SVD)\n",
    "# ===================================================================\n",
    "svd_model = None\n",
    "if HAS_SURPRISE:\n",
    "    reader = Reader(rating_scale=(0.5, 5.0))\n",
    "    data = Dataset.load_from_df(df[[\"user_id\", \"item_id\", \"rating_aug\"]], reader)\n",
    "    trainset = data.build_full_trainset()\n",
    "    svd_model = SVD(n_factors=64, n_epochs=20, random_state=42)\n",
    "    svd_model.fit(trainset)\n",
    "    print(\"âœ… SVD ëª¨ë¸ í•™ìŠµ ì™„ë£Œ.\")\n",
    "\n",
    "def recommend_collaborative_filtering(user_id: str, all_items: list) -> Dict[str, float]:\n",
    "    if svd_model is None: return {}\n",
    "    predictions = [(item, float(svd_model.predict(user_id, item).est)) for item in all_items]\n",
    "    return dict(predictions)\n",
    "\n",
    "print(\"âœ… í˜‘ì—… í•„í„°ë§ ì¶”ì²œ í•¨ìˆ˜ ì •ì˜ ì™„ë£Œ.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… ì œí’ˆë³„ í”¼ë¶€ í”„ë¡œí•„(íƒ€ì…, í†¤, ê³ ë¯¼) ì§‘ê³„ ì™„ë£Œ.\n",
      "âœ… í”¼ë¶€ ì í•©ë„(íƒ€ì…, í†¤, ê³ ë¯¼) ê¸°ë°˜ í•„í„°ë§ í•¨ìˆ˜ ì •ì˜ ì™„ë£Œ.\n"
     ]
    }
   ],
   "source": [
    "# ===================================================================\n",
    "# 5. í”¼ë¶€ ì í•©ë„ ë¶„ì„ ë° í•„í„°ë§ í•¨ìˆ˜ (ìˆ˜ì •)\n",
    "# ===================================================================\n",
    "# (ìˆ˜ì •) skin_concerns ì»¬ëŸ¼ì„ ì‚¬ìš©í•˜ë„ë¡ ë³€ê²½\n",
    "for col in [\"skin_type\", \"skin_tone\", \"skin_concerns\"]:\n",
    "    if col in df.columns:\n",
    "        df[col] = df[col].fillna(\"Unknown\").astype(str)\n",
    "\n",
    "def get_ratio_pivot(df: pd.DataFrame, column_name: str) -> pd.DataFrame:\n",
    "    if column_name not in df.columns:\n",
    "        return pd.DataFrame(index=item_text_df[\"item_id\"])\n",
    "    counts = df.groupby([\"item_id\", column_name])[\"user_id\"].count().reset_index(name=\"count\")\n",
    "    totals = counts.groupby(\"item_id\")[\"count\"].transform(\"sum\").clip(lower=1)\n",
    "    counts[\"ratio\"] = counts[\"count\"] / totals\n",
    "    pivot = counts.pivot(index=\"item_id\", columns=column_name, values=\"ratio\").fillna(0.0)\n",
    "    return pivot.reindex(item_text_df[\"item_id\"]).fillna(0.0)\n",
    "\n",
    "R_skin_type = get_ratio_pivot(df, \"skin_type\")\n",
    "R_skin_tone = get_ratio_pivot(df, \"skin_tone\")\n",
    "# (ìˆ˜ì •) skin_concerns ì»¬ëŸ¼ìœ¼ë¡œ í”¼ë´‡ í…Œì´ë¸” ìƒì„±\n",
    "R_skin_concerns = get_ratio_pivot(df, \"skin_concerns\") \n",
    "\n",
    "print(\"âœ… ì œí’ˆë³„ í”¼ë¶€ í”„ë¡œí•„(íƒ€ì…, í†¤, ê³ ë¯¼) ì§‘ê³„ ì™„ë£Œ.\")\n",
    "\n",
    "# (ìˆ˜ì •) í•„í„°ë§ í•¨ìˆ˜ê°€ skin_concerns ì»¬ëŸ¼ì„ ì‚¬ìš©í•˜ë„ë¡ ë³€ê²½\n",
    "def filter_items_by_skin_compatibility(user_id: str, threshold: float = 0.1) -> set:\n",
    "    user_info = df[df.user_id == user_id].tail(1)\n",
    "    if user_info.empty:\n",
    "        return set(item_text_df[\"item_id\"])\n",
    "\n",
    "    user_skin_type = str(user_info.skin_type.values[0])\n",
    "    user_skin_tone = str(user_info.skin_tone.values[0])\n",
    "    user_concern = str(user_info.skin_concerns.values[0]) # skin_concerns ì‚¬ìš©\n",
    "    \n",
    "    candidate_items = set()\n",
    "    \n",
    "    if user_skin_type in R_skin_type.columns:\n",
    "        candidate_items.update(R_skin_type[R_skin_type[user_skin_type] >= threshold].index)\n",
    "    if user_skin_tone in R_skin_tone.columns:\n",
    "        candidate_items.update(R_skin_tone[R_skin_tone[user_skin_tone] >= threshold].index)\n",
    "    # (ìˆ˜ì •) R_skin_concerns í”¼ë´‡ í…Œì´ë¸”ì„ ì‚¬ìš©í•˜ì—¬ í•„í„°ë§\n",
    "    if user_concern in R_skin_concerns.columns:\n",
    "        candidate_items.update(R_skin_concerns[R_skin_concerns[user_concern] >= threshold].index)\n",
    "        \n",
    "    return candidate_items if candidate_items else set(item_text_df[\"item_id\"])\n",
    "\n",
    "print(\"âœ… í”¼ë¶€ ì í•©ë„(íƒ€ì…, í†¤, ê³ ë¯¼) ê¸°ë°˜ í•„í„°ë§ í•¨ìˆ˜ ì •ì˜ ì™„ë£Œ.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… í”¼ë¶€ í•„í„°ë§ ê¸°ë°˜ í•˜ì´ë¸Œë¦¬ë“œ ì¶”ì²œ í•¨ìˆ˜ ì •ì˜ ì™„ë£Œ.\n"
     ]
    }
   ],
   "source": [
    "# ===================================================================\n",
    "# 6. ìµœì¢… í•˜ì´ë¸Œë¦¬ë“œ ì¶”ì²œ\n",
    "# ===================================================================\n",
    "def normalize_scores(score_dict: Dict) -> Dict:\n",
    "    if not score_dict: return {}\n",
    "    values = np.array(list(score_dict.values()), dtype=float)\n",
    "    min_val, max_val = values.min(), values.max()\n",
    "    if max_val - min_val < 1e-8: return {k: 0.5 for k in score_dict}\n",
    "    return {k: float((v - min_val) / (max_val - min_val)) for k, v in score_dict.items()}\n",
    "\n",
    "def recommend_hybrid_skin_filtered(user_id: str, k: int = 10, content_weight: float = 0.5, skin_filter_threshold: float = 0.1):\n",
    "    candidate_items = filter_items_by_skin_compatibility(user_id, threshold=skin_filter_threshold)\n",
    "    print(f\"ğŸ‘¤ ì‚¬ìš©ì '{user_id}'ì˜ í”¼ë¶€ ì •ë³´ì™€ ë§ëŠ” í›„ë³´ ì œí’ˆ {len(candidate_items)}ê°œë¥¼ í•„í„°ë§í–ˆìŠµë‹ˆë‹¤.\")\n",
    "    if not candidate_items:\n",
    "        print(\"âš ï¸ í”¼ë¶€ì— ë§ëŠ” ì œí’ˆì„ ì°¾ì§€ ëª»í•´ ì „ì²´ ì œí’ˆì„ ëŒ€ìƒìœ¼ë¡œ ì¶”ì²œí•©ë‹ˆë‹¤.\")\n",
    "        candidate_items = set(item_text_df[\"item_id\"])\n",
    "\n",
    "    seen_items = set(df.loc[df.user_id == user_id, \"item_id\"])\n",
    "    candidate_items = list(candidate_items - seen_items)\n",
    "\n",
    "    content_scores_all = recommend_content_based(df, user_id)\n",
    "    cf_scores_all = recommend_collaborative_filtering(user_id, item_text_df[\"item_id\"].tolist())\n",
    "    \n",
    "    content_scores = {item: score for item, score in content_scores_all.items() if item in candidate_items}\n",
    "    cf_scores = {item: score for item, score in cf_scores_all.items() if item in candidate_items}\n",
    "    \n",
    "    content_scores_norm = normalize_scores(content_scores)\n",
    "    cf_scores_norm = normalize_scores(cf_scores)\n",
    "    \n",
    "    final_scores = []\n",
    "    for item in candidate_items:\n",
    "        score = (\n",
    "            content_weight * content_scores_norm.get(item, 0) +\n",
    "            (1 - content_weight) * cf_scores_norm.get(item, 0)\n",
    "        )\n",
    "        final_scores.append((item, score))\n",
    "        \n",
    "    final_scores.sort(key=lambda x: x[1], reverse=True)\n",
    "    \n",
    "    return pd.DataFrame(final_scores[:k], columns=[\"item_id\", \"final_score\"])\n",
    "\n",
    "print(\"âœ… í”¼ë¶€ í•„í„°ë§ ê¸°ë°˜ í•˜ì´ë¸Œë¦¬ë“œ ì¶”ì²œ í•¨ìˆ˜ ì •ì˜ ì™„ë£Œ.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- [ìµœì¢… ê²°ê³¼] í”¼ë¶€ í•„í„°ë§ ê¸°ë°˜ í•˜ì´ë¸Œë¦¬ë“œ ì¶”ì²œ ---\n",
      "í”¼ë¶€ í•„í„°ë§ ê¸°ì¤€(threshold): íŠ¹ì • í”¼ë¶€íƒ€ì…/í†¤/ê³ ë¯¼ì„ ê°€ì§„ ë¦¬ë·°ì–´ ë¹„ìœ¨ì´ 10% ì´ìƒì¸ ì œí’ˆë§Œ í›„ë³´ë¡œ ì„ ì •\n",
      "ğŸ‘¤ ì‚¬ìš©ì 'vwaaang'ì˜ í”¼ë¶€ ì •ë³´ì™€ ë§ëŠ” í›„ë³´ ì œí’ˆ 12ê°œë¥¼ í•„í„°ë§í–ˆìŠµë‹ˆë‹¤.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>item_id</th>\n",
       "      <th>final_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ë§ˆëª½ë“œ ë¸”ë£¨ ìºëª¨ë§ˆì¼ í¬ë¦¼ 60ml ê¸°íš (+30ml)</td>\n",
       "      <td>0.879244</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[ì•„ë‘ PICK] ë‚«ì¸  ì„¼í…”ë¼ìŠ¤ì¹´ ì—°ê³  ì¼ë‘ì¼ë‘ 15g</td>\n",
       "      <td>0.832843</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[ì†ìƒ/ì¥ë²½ ë¦¬í˜ì–´] ì•„ë²¤ëŠ ì‹œì¹¼íŒŒíŠ¸ í”ŒëŸ¬ìŠ¤ SOS ë¦¬í˜ì–´ í¬ë¦¼ 100ml 2ì… ê¸°íš</td>\n",
       "      <td>0.752454</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ì´ì¦ˆì•¤íŠ¸ë¦¬ ì–´ë‹ˆì–¸ ë‰´í˜ì–´ ê²”í¬ë¦¼ 80ml ëŒ€ìš©ëŸ‰ ê¸°íš (+ê²”í¬ë¦¼20ml+íŒ¨ë“œ2ë§¤)</td>\n",
       "      <td>0.726204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[ì‘ê¸‰ì§„ì •/38% ì—¬ë“œë¦„ ê°œì„ ] ë¡œë²¡í‹´ ì‹œì¹´ì¼€ì–´ ë¸”ë ˆë¯¸ì‰¬ í´ë¦¬ì–´ë§ í¬ë¦¼ 50ml ë¦¬...</td>\n",
       "      <td>0.654759</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>[ê°•í¬ì¬í”½/ì¶”ê°€ì¦ì •í•œì •ê¸°íš] ì•„ë²¤ëŠ ì‹œì¹¼íŒŒíŠ¸ í”ŒëŸ¬ìŠ¤ S.O.S í¬ë¦¼ 100ml 2ì…...</td>\n",
       "      <td>0.621607</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>í‚¤ì—˜ ìš¸íŠ¸ë¼ í›¼ì´ì…œ í¬ë¦¼ 28ml</td>\n",
       "      <td>0.599900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>[ëŒ€ìš©ëŸ‰ê¸°íš] í•œìœ¨ ì‘¥ì‹œì¹´ ìˆ˜ë¶„í¬ë¦¼ 110ml (+25ml+ íŒ¨ë“œ2ë§¤+í¡ì°©íŒ©í¼2ml)</td>\n",
       "      <td>0.578260</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>í‚¤ì—˜ ìš¸íŠ¸ë¼ í›¼ì´ì…œ ì˜¤ì¼-í”„ë¦¬ ì ¤ í¬ë¦¼ 50ml</td>\n",
       "      <td>0.400000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>[ê¹€ê³ ì€ Pick] ê°€íˆ ì—‘ìŠ¤í‹´Cë°¤</td>\n",
       "      <td>0.362142</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             item_id  final_score\n",
       "0                     ë§ˆëª½ë“œ ë¸”ë£¨ ìºëª¨ë§ˆì¼ í¬ë¦¼ 60ml ê¸°íš (+30ml)     0.879244\n",
       "1                     [ì•„ë‘ PICK] ë‚«ì¸  ì„¼í…”ë¼ìŠ¤ì¹´ ì—°ê³  ì¼ë‘ì¼ë‘ 15g     0.832843\n",
       "2    [ì†ìƒ/ì¥ë²½ ë¦¬í˜ì–´] ì•„ë²¤ëŠ ì‹œì¹¼íŒŒíŠ¸ í”ŒëŸ¬ìŠ¤ SOS ë¦¬í˜ì–´ í¬ë¦¼ 100ml 2ì… ê¸°íš     0.752454\n",
       "3      ì´ì¦ˆì•¤íŠ¸ë¦¬ ì–´ë‹ˆì–¸ ë‰´í˜ì–´ ê²”í¬ë¦¼ 80ml ëŒ€ìš©ëŸ‰ ê¸°íš (+ê²”í¬ë¦¼20ml+íŒ¨ë“œ2ë§¤)     0.726204\n",
       "4  [ì‘ê¸‰ì§„ì •/38% ì—¬ë“œë¦„ ê°œì„ ] ë¡œë²¡í‹´ ì‹œì¹´ì¼€ì–´ ë¸”ë ˆë¯¸ì‰¬ í´ë¦¬ì–´ë§ í¬ë¦¼ 50ml ë¦¬...     0.654759\n",
       "5  [ê°•í¬ì¬í”½/ì¶”ê°€ì¦ì •í•œì •ê¸°íš] ì•„ë²¤ëŠ ì‹œì¹¼íŒŒíŠ¸ í”ŒëŸ¬ìŠ¤ S.O.S í¬ë¦¼ 100ml 2ì…...     0.621607\n",
       "6                                 í‚¤ì—˜ ìš¸íŠ¸ë¼ í›¼ì´ì…œ í¬ë¦¼ 28ml     0.599900\n",
       "7    [ëŒ€ìš©ëŸ‰ê¸°íš] í•œìœ¨ ì‘¥ì‹œì¹´ ìˆ˜ë¶„í¬ë¦¼ 110ml (+25ml+ íŒ¨ë“œ2ë§¤+í¡ì°©íŒ©í¼2ml)     0.578260\n",
       "8                         í‚¤ì—˜ ìš¸íŠ¸ë¼ í›¼ì´ì…œ ì˜¤ì¼-í”„ë¦¬ ì ¤ í¬ë¦¼ 50ml     0.400000\n",
       "9                                [ê¹€ê³ ì€ Pick] ê°€íˆ ì—‘ìŠ¤í‹´Cë°¤     0.362142"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# ===================================================================\n",
    "# 7. ì¶”ì²œ ì‹œìŠ¤í…œ ì‹¤í–‰ ì˜ˆì‹œ\n",
    "# ===================================================================\n",
    "if not df.empty:\n",
    "    example_user_id = df[\"user_id\"].iloc[0]\n",
    "\n",
    "    print(f\"\\n--- [ìµœì¢… ê²°ê³¼] í”¼ë¶€ í•„í„°ë§ ê¸°ë°˜ í•˜ì´ë¸Œë¦¬ë“œ ì¶”ì²œ ---\")\n",
    "    print(f\"í”¼ë¶€ í•„í„°ë§ ê¸°ì¤€(threshold): íŠ¹ì • í”¼ë¶€íƒ€ì…/í†¤/ê³ ë¯¼ì„ ê°€ì§„ ë¦¬ë·°ì–´ ë¹„ìœ¨ì´ 10% ì´ìƒì¸ ì œí’ˆë§Œ í›„ë³´ë¡œ ì„ ì •\")\n",
    "\n",
    "    recommendations = recommend_hybrid_skin_filtered(\n",
    "        user_id=example_user_id, \n",
    "        k=10, \n",
    "        content_weight=0.6, \n",
    "        skin_filter_threshold=0.1\n",
    "    )\n",
    "\n",
    "    display(recommendations)\n",
    "else:\n",
    "    print(\"ë°ì´í„°í”„ë ˆì„ì´ ë¹„ì–´ ìˆì–´ ì¶”ì²œì„ ì‹¤í–‰í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
