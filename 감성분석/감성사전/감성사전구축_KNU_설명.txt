================================================================================
                    감성사전구축_KNU.ipynb 코드 분석 및 설명
================================================================================

1. 프로젝트 개요
================================================================================

이 프로젝트는 한국어 감성 분석을 위한 KNU(Korean Sentiment Lexicon) 감성사전을 구축하고 
성능을 평가하는 과정을 담고 있습니다.

주요 특징:
- 한국어 전용: 한국어의 특성을 고려한 감성사전
- 품사별 분류: 명사, 동사, 형용사, 부사 등 품사별로 감성 단어 분류
- 긍정/부정 레이블: 각 단어에 긍정(1) 또는 부정(0) 레이블 부여
- 학술적 기반: 한국어 자연어처리 연구에서 널리 사용되는 표준 사전

2. 데이터 구조 및 전처리
================================================================================

2.1 입력 데이터
- Ntoken_review.csv: 형태소 분석이 완료된 리뷰 데이터
- pos_pol_word.txt: 긍정 감성 단어 사전
- neg_pol_word.txt: 부정 감성 단어 사전

2.2 데이터 전처리 과정
- 평점을 긍정/부정으로 변환 (4점 이상 = 긍정, 4점 미만 = 부정)
- tokens 컬럼의 문자열을 리스트로 파싱
- 1000개 샘플로 데이터 크기 조정

3. 단계별 코드 분석
================================================================================

3.1 1단계: total_test_tokens.csv 생성
================================================================================

목적: 형태소 분석된 리뷰 데이터를 감성 분석에 적합한 형태로 변환
 4점 이
주요 코드:
```python
def convert_rating_to_sentiment(rating):
    if rating >= 4:
        return 1.0  # 긍정
    else:
        return 0.0  # 부정

df['pos_neg'] = df['rating'].apply(convert_rating_to_sentiment)
df['sen'] = df['tokens'].apply(literal_eval)
```

처리 결과:
- 테스트 데이터 크기: (1000, 2)
- 긍정 리뷰: 947개 (94.7%)
- 부정 리뷰: 53개 (5.3%)

3.2 2단계: 긍정사전 구축
================================================================================

목적: 긍정 감성 단어들을 품사별로 분류하고 n-gram 형태로 정리

주요 코드:
```python
tag_list = ['NNG', 'NNP', 'VV', 'VA', 'XR', 'MAG']
pos_token = [komoran.pos(token) for token in lines]
pos_token_list = [[token[0] for token in tokens if token[1] in tag_list] 
                  for tokens in pos_token]
```

품사 태그 설명:
- NNG: 일반 명사
- NNP: 고유 명사
- VV: 동사
- VA: 형용사
- XR: 어근
- MAG: 일반 부사

처리 결과:
- 긍정사전 토큰 수: 3,195개
- 1-gram 긍정사전: 967개
- 2-gram 긍정사전: 2,137개
- 3-gram 긍정사전: 75개

3.3 3단계: 부정사전 구축
================================================================================

목적: 부정 감성 단어들을 품사별로 분류하고 n-gram 형태로 정리

추가 부정 단어:
```python
neg_add = ['모르', '안', '아쉽', '별로', '그냥', '하', '따갑', '광고', '딱히', '나쁘', 
           '올라오', '기름', '부족', '못', '겉돌', '아직', '심하', '밀리', '열', '유분', 
           '뒤집', '떨어지', '불편', '비싸', '단점', '잘못', '어렵', '땡기', '싫']
```

처리 결과:
- 부정사전 토큰 수: 6,052개
- 1-gram 부정사전: 1,921개
- 2-gram 부정사전: 3,798개
- 3-gram 부정사전: 302개

3.4 4단계: 1-gram 성능 평가
================================================================================

목적: 1-gram 기반 감성 분석 모델의 성능을 평가

감성 점수 계산 로직:
```python
for i in range(len(test_sent)):
    for word in test_sent.loc[i, 'sen2']:
        if word in pos_dict1:
            test_sent.loc[i, 'senti_score'] += 1  # 긍정 단어 +1
        elif word in neg_dict1:
            test_sent.loc[i, 'senti_score'] -= 1  # 부정 단어 -1
```

성능 결과:
- 정확도: 64.50%
- 긍정 예측: 650개
- 부정 예측: 350개

분류 보고서 분석:
- 부정 클래스(0.0): 정밀도 0.07, 재현율 0.45, F1-score 0.12
- 긍정 클래스(1.0): 정밀도 0.96, 재현율 0.66, F1-score 0.78

3.5 5단계: 1-gram + 2-gram + 3-gram 성능 평가
================================================================================

목적: n-gram 조합을 통한 감성 분석 모델의 성능 향상

처리 순서:
1. 3-gram 처리 (가장 긴 구문부터)
2. 2-gram 처리 (매칭된 토큰은 빈 문자열로 대체)
3. 1-gram 처리 (남은 단어들)

성능 결과:
- 정확도: 65.20% (1-gram 대비 0.7% 향상)
- 긍정 예측: 653개
- 부정 예측: 347개

4. 성능 분석 및 개선점
================================================================================

4.1 현재 성능의 한계
- 부정 리뷰의 낮은 재현율 (0.49)
- 긍정 리뷰에 대한 높은 정밀도 (0.96) vs 낮은 재현율 (0.66)
- 데이터 불균형 문제 (긍정:부정 = 94.7:5.3)

4.2 개선 방안
1. 데이터 불균형 해결
   - 부정 리뷰 데이터 증강
   - 가중치 조정
   - 언더샘플링/오버샘플링

2. 감성사전 확장
   - 도메인 특화 단어 추가
   - 문맥 의존적 감성 분석
   - 부정어 처리 개선

3. 모델 개선
   - 딥러닝 모델 적용
   - 앙상블 방법 사용
   - 하이퍼파라미터 튜닝

5. 파일 구조 및 출력물
================================================================================

입력 파일:
- Ntoken_review.csv: 형태소 분석된 리뷰 데이터
- pos_pol_word.txt: 긍정 감성 단어 사전
- neg_pol_word.txt: 부정 감성 단어 사전

출력 파일:
- total_test_tokens.csv: 전처리된 테스트 데이터
- senti_labeled_df.csv: 감성 분석 결과가 포함된 최종 데이터

6. 기술적 특징
================================================================================

6.1 형태소 분석기
- KoNLPy의 Komoran 사용
- 한국어 특성에 최적화된 형태소 분석

6.2 n-gram 처리
- 3-gram → 2-gram → 1-gram 순서로 처리
- 긴 구문 우선 매칭으로 정확도 향상

6.3 감성 점수 계산
- 단순 가중치 방식 (+1/-1)
- 임계값 기반 분류 (0 초과 = 긍정)

7. 활용 방안
================================================================================

7.1 피부 질환 관련 리뷰 분석
- 화장품 효과성 평가
- 부작용 감지
- 고객 만족도 분석

7.2 시스템 개선
- 실시간 리뷰 모니터링
- 제품 추천 시스템
- 고객 서비스 개선

8. 결론
================================================================================

이 프로젝트는 한국어 감성 분석을 위한 기본적인 사전 기반 접근법을 구현했습니다.
현재 65.2%의 정확도를 보이고 있으나, 데이터 불균형과 도메인 특화 문제로 
추가적인 개선이 필요합니다.

주요 성과:
- 체계적인 감성사전 구축
- n-gram 기반 감성 분석 구현
- 성능 평가 및 시각화

향후 과제:
- 딥러닝 모델 적용
- 도메인 특화 사전 확장
- 실시간 처리 시스템 구축

